{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interferometryData import InterferometryData\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3244f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetInterferometry:\n",
    "    def __init__(self,\n",
    "                    size_figure,\n",
    "                    type_psf,\n",
    "                    perc_train = 0.7,\n",
    "                    perc_validation = 0.25,\n",
    "                    perc_test = 0.05,\n",
    "                    batch_train = 10,\n",
    "                    batch_validation = 10,\n",
    "                    batch_test = 1\n",
    "                    path_images = None,\n",
    "                    path_convolution = None,\n",
    "                    path_psf = None,\n",
    "                ):\n",
    "        self.size_figure = size_figure\n",
    "        self.type_psf = type_psf\n",
    "        self.path_images = self.init_path_images(path_images)\n",
    "        self.path_convolution  self.init_path_convolution(path_convolution)\n",
    "        self.path_psf = self.init_path_psf(path_psf)\n",
    "        self.perc_train = perc_train\n",
    "        self.perc_validation = perc_validation\n",
    "        self.perc_test = perc_test\n",
    "        self.batch_train = batch_train\n",
    "        self.batch_test = batch_test\n",
    "        self.batch_validation = batch_validation\n",
    "        \n",
    "    def init_path_images(self,path_save):\n",
    "        if (path_save == None):\n",
    "            return'../datasets/images_'+str(self.size_figure)+'x'+str(self.size_figure)+'/images'\n",
    "        else:\n",
    "            return path_save  \n",
    "    def init_path_convolution(self,path_convolution):\n",
    "        if (path_convolution == None):\n",
    "            return '../datasets/images_'+str(self.size_figure)+'x'+str(self.size_figure)+'/convolutions/'+self.type_psf+'/conv'\n",
    "        else \n",
    "            return path_convolution\n",
    "    \n",
    "    def init_path_psf (self,path_psf):\n",
    "        if (path_psf == None):\n",
    "            return '../datasets/images_'+str(self.size_figure)+'x'+str(self.size_figure)+'/convolutions/'+self.type_psf+'/psf'\n",
    "        else:\n",
    "            return path_psf\n",
    "\n",
    "    def tsfms(self):\n",
    "        return transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def create_train_data(self,start,step):\n",
    "        size_train = round(step*self.perc_train)\n",
    "        batch_train_size=  BATCH_TRAIN \n",
    "        params = ParamsEllipses(self.size_figure)\n",
    "\n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.create(size_image=self.size_figure,params = params , start = start,stop = start +step)\n",
    "\n",
    "        data_psf = DatasetPSF(self.size_figure,self.type_psf)\n",
    "        data_psf.create(N,TYPE_PSF)\n",
    "\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf,data_psf.image)\n",
    "        data_dirty.create(images = data_image.images,size_image = self.size_figure, type_psf = self.type_psf, psf =data_psf.image)\n",
    "        trainSet=interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        trainLoader=DataLoader(trainSet,self.batch_train,shuffle=True)\n",
    "        return trainLoader\n",
    "    \n",
    "    \n",
    "    def create_validation_data(self,start,step):\n",
    "        start = start + round(step*self.perc_train)\n",
    "        size_validation =  round(step*self.perc_validation)\n",
    "\n",
    "        params = ParamsEllipses(self.size_figure)\n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.create(size_image=self.size_figure,params = params , start = start,stop = start +size_validation)\n",
    "\n",
    "        data_psf = DatasetPSF(self.size_figure,self.type_psf)\n",
    "        data_psf.create(self.size_figure,self.type_psf)\n",
    "\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf,data_psf.image)\n",
    "        data_dirty.create(images = data_image.images,size_image = self.size, type_psf = self.type_psf, psf =data_psf.image)\n",
    "        validationSet = interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        validationLoader=DataLoader(validationSet,self.batch_validation,shuffle=True)\n",
    "        return validationLoader\n",
    "\n",
    "     def create_test_data(self,start,step):\n",
    "        start = start + round(step*self.perc_train) + round(step*self.perc_validation)\n",
    "        size_test =  round(step*self.perc_test)\n",
    "\n",
    "        params = ParamsEllipses(self.size_figure)\n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.create(size_image=self.size_figure,params = params , start = start,stop = start +size_test)\n",
    "\n",
    "        data_psf = DatasetPSF(self.size_figure,self.type_psf)\n",
    "        data_psf.create(self.size_figure,self.type_psf)\n",
    "\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf,data_psf.image)\n",
    "        data_dirty.create(images = data_image.images,size_image = self.size, type_psf = self.type_psf, psf =data_psf.image)\n",
    "        testSet = interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        testLoader=DataLoader(testSet,self.batch_test,shuffle=True)\n",
    "        return testLoader\n",
    "    \n",
    "    \n",
    "    def read_train_data(self,start,stop):\n",
    "        size = start- stop  #size of lot of the dataset\n",
    "        size_train = round(size*self.perc_train)\n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.read(size_image=self.size_figure, start = start,stop = start+size_train)\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf)\n",
    "        data_dirty.read(size_image = self.size_figure, type_psf = self.type_psf,start = start, stop = start + size_train)\n",
    "        trainSet= interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        trainLoader=DataLoader(trainSet,self.batch_train,shuffle=True)\n",
    "        return trainLoader\n",
    "    \n",
    "    def read_validation_data(self,start,stop):\n",
    "        size = start- stop  \n",
    "        size_validation = round(size*self.perc_validation)\n",
    "        size_train = round(size*self.perc_train)\n",
    "        start = start + size_train\n",
    "    \n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.read(size_image=self.size_figure, start = start,stop = start+size_validation)\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf)\n",
    "        data_dirty.read(size_image = self.size_figure, type_psf = self.type_psf,start = start, stop = start + size_validation)\n",
    "        validationSet= interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        validationLoader=DataLoader(validationSet,self.batch_validation,shuffle=True)\n",
    "        return validationLoader\n",
    "    \n",
    "\n",
    "    def read_test_data(self,start,stop):\n",
    "        size = start- stop \n",
    "        size_test = round(size*self.perc_test)\n",
    "        size_train = round(size*self.perc_train)\n",
    "        size_validation = round(size*self.perc_train)\n",
    "        start = start + size_train +size_validation\n",
    "        data_image = DatasetImages(self.size_figure)\n",
    "        data_image.read(size_image=self.size_figure, start = start,stop = start+size_test)\n",
    "        data_dirty = DatasetDirty(self.size_figure,self.type_psf)\n",
    "        data_dirty.read(size_image = self.size_figure, type_psf = self.type_psf,start = start, stop = start + size_test)\n",
    "        testSet= interferometryData(data_dirty.dirtys,data_image.images,self.tsfms())\n",
    "        testLoader=DataLoader(testSet,self.batch_validation,shuffle=True)\n",
    "        return testLoader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
