{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOysBVxXLNDq"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DiLRQ-sM0Cg"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJh6KJu2LCtT",
    "outputId": "f822dbc3-1276-4193-996a-09215447f4bc"
   },
   "outputs": [],
   "source": [
    "#Download\n",
    "     #tqdm\n",
    "     #torchvision\n",
    "     #cv2   \n",
    "#Pytorch dataset \n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Deep Learning\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "#images#\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#sesion save# \n",
    "import dill\n",
    "\n",
    "#\n",
    "from datasetImages import DatasetImages\n",
    "from datasetDirty import DatasetDirty\n",
    "import cupy as cp\n",
    "\n",
    "# Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hy61KC0N940"
   },
   "source": [
    "**Params Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xWbxZ_iuN9dF"
   },
   "outputs": [],
   "source": [
    "N = 25 # image size\n",
    "N_PSF = 25 # psf size\n",
    "TYPE_PSF = 'psf_gauss_'+str(N)+'x'+str(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9fjBnRQNr13"
   },
   "source": [
    "**Params Dataset Python**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "84_mVq1RNrEr"
   },
   "outputs": [],
   "source": [
    "PATH_IMAGES = '../datasets/images_'+str(N)+'x'+str(N)+'/images' #path dataset images\n",
    "PATH_CONVOLUTION = '../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/conv'#path dataset convolution\n",
    "PATH_PSF_SAVE =  '../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/psf'#path convolution\n",
    "INITIAL_DATASET = 0  #initial index for the names of the saved images \n",
    "FINAL_DATASET =  100#final index for the names of the saved images \n",
    "PERC_TRAIN = 0.7 # (70%) #train percentage \n",
    "PERC_VAL = 0.25 #  (25#) #validation percentage\n",
    "PERC_TEST =  0.05 # (5%) #test percentag\n",
    "\n",
    "BATCH_TRAIN = 100\n",
    "BATCH_VALIDATION = 100 #batch sizeimages\n",
    "BATCH_TEST = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q228E724M150"
   },
   "source": [
    "**Params Dataset Python**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Q5Y1eteM1-H"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "size_data= FINAL_DATASET - INITIAL_DATASET\n",
    "PATH_VALIDATION =  '../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/models/model_S'+str(size_data)+'_B'+str(BATCH_TRAIN)+'_N'+str(NUM_EPOCHS)+'/validation'\n",
    "PATH_TEST =  '../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/models/model_S'+str(size_data)+'_B'+str(BATCH_TRAIN)+'_N'+str(NUM_EPOCHS)+'/test'\n",
    "PATH_GRAPH ='../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/models/model_S'+str(size_data)+'_B'+str(BATCH_TRAIN)+'_N'+str(NUM_EPOCHS)+'/graph'\n",
    "PATH_MODEL_SAVE ='../datasets/images_'+str(N)+'x'+str(N)+'/convolutions/'+TYPE_PSF+'/models/model_S'+str(size_data)+'_B'+str(BATCH_TRAIN)+'_N'+str(NUM_EPOCHS)+'/model' #path where the dataset convolution is saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzeBIRG0SfZ7"
   },
   "source": [
    "**Auxiliary functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sttjNq8HVV0D"
   },
   "source": [
    "TODO: comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "voP0tAiDVWaH"
   },
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, N, N)\n",
    "    save_image(img, name)\n",
    "    \n",
    "def make_dir(path):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_two(a, b, title1 = \"Original\", title2 = \"Edited\"):\n",
    "    plt.subplot(121), plt.imshow(a), plt.title(title1)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(b), plt.title(title2)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# Display one image\n",
    "def display(a, title1 = \"Original\"):\n",
    "    plt.imshow(a), plt.title(title1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iLIDr8ESZ8s"
   },
   "source": [
    "display fit image from a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKW5tIafnchl"
   },
   "source": [
    "# Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqr7H_C219Pm"
   },
   "source": [
    "**Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2lHn9pxnvMl",
    "outputId": "572845b4-b0a6-4e5b-f921-340dc7f6a719"
   },
   "outputs": [],
   "source": [
    "size = FINAL_DATASET- INITIAL_DATASET  #size of lot of the dataset\n",
    "size_train = round(size*PERC_TRAIN)\n",
    "size_validation =  round(size*PERC_VAL)\n",
    "size_test =  round(size*PERC_TEST)  \n",
    "batch_train_size=  BATCH_TRAIN \n",
    "batch_test_size=  BATCH_TEST\n",
    "batch_validation_size=  BATCH_VALIDATION\n",
    "data_image = DatasetImages(N)\n",
    "data_image = data_image.read(size_image=N, start = INITIAL_DATASET,stop = FINAL_DATASET)\n",
    "data_dirty = DatasetDirty(N,TYPE_PSF)\n",
    "data_dirty=data_dirty.read(size_image = N, type_psf = TYPE_PSF,start = INITIAL_DATASET, stop = FINAL_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1eGRAkE4-Wa"
   },
   "source": [
    "TODO: Comentar como en tutorial (DATAset create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized\n"
     ]
    }
   ],
   "source": [
    "print(\"finalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QkD8WPsiiarU"
   },
   "outputs": [],
   "source": [
    "class interferometryDataset(Dataset):\n",
    "  def __init__(self,datasetnoised,datasetclean,transform):\n",
    "    self.noise=datasetnoised\n",
    "    self.clean=datasetclean\n",
    "    self.transform=transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.noise)\n",
    "  \n",
    "  def __getitem__(self,idx):\n",
    "    xNoise=self.noise[idx]\n",
    "    xClean=self.clean[idx]\n",
    "    \n",
    "    if self.transform != None:\n",
    "      xNoise=self.transform(xNoise)\n",
    "      xClean=self.transform(xClean)\n",
    "\n",
    "    return (xNoise,xClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF5t_mpl4WmG"
   },
   "source": [
    "we define the transforms for the images of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gs0CuSl-4WcR"
   },
   "outputs": [],
   "source": [
    "tsfms=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bFH3U2v48ZF"
   },
   "source": [
    "we divide the images into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "e4xkNrSrlVsp"
   },
   "outputs": [],
   "source": [
    "train_dirty = data_dirty[0:size_train]\n",
    "train_images = data_image[0:size_train]\n",
    "\n",
    "validation_dirty = data_dirty[size_train:size_train+size_validation]\n",
    "validation_image = data_image[size_train:size_train+size_validation]\n",
    "\n",
    "\n",
    "test_dirty = data_dirty[size_validation:size_validation+size_test]\n",
    "test_image = data_image[size_validation:size_validation+size_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecpnycPc6Zs4"
   },
   "source": [
    "we generate the dataset using `Dataloard` that eases the task of making iterable training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CeibVshrkm8P"
   },
   "outputs": [],
   "source": [
    "trainSet=interferometryDataset(train_dirty,train_images,tsfms)\n",
    "validationSet = interferometryDataset(validation_dirty,validation_image,tsfms)\n",
    "testSet=interferometryDataset(test_dirty,test_image,tsfms)\n",
    "\n",
    "\n",
    "trainLoader=DataLoader(trainSet,batch_train_size,shuffle=True)\n",
    "validationLoader=DataLoader(validationSet,batch_validation_size,shuffle=True)\n",
    "testLoader=DataLoader(testSet,batch_test_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE5ARIWkoTtL"
   },
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrO14pTK7oNR"
   },
   "source": [
    "**Auxiliary functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMXYUFfY7zjD"
   },
   "source": [
    "returns the CUDA GPU device or the CPU depending upon the availability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-u8aSC_X7yhX"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaY4Py3D99RD"
   },
   "source": [
    "TODO: Comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbchWHocox71",
    "outputId": "f8976d61-5660-4523-e9e7-cd0b6517e94e"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # encoder layers\n",
    "        self.enc1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.enc2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.enc3 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.enc4 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.dec1 = nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2)  \n",
    "        self.dec2 = nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2)\n",
    "        self.dec3 = nn.ConvTranspose2d(16, 32, kernel_size=2, stride=2)\n",
    "        self.dec4 = nn.ConvTranspose2d(32, 64, kernel_size=2, stride=1)\n",
    "        self.dec4 = nn.ConvTranspose2d(32, 64, kernel_size=2, stride=1)\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=2, padding=13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = self.pool(x) # the latent space representation\n",
    "        \n",
    "        # decode\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "net = Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTYhgJFfW2h-"
   },
   "source": [
    "TODO_ comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "RmsbxIylo0WH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# the optimizaater\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAIuS9ASW1dl"
   },
   "source": [
    "TODO_ comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lT3qExQxo19c"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader,validationloader, NUM_EPOCHS,path):\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        for dirty,clean in tqdm((trainloader)):\n",
    "            dirty,clean=dirty.to(device),clean.to(device)\n",
    "            optimizer.zero_grad()            \n",
    "            outputs = net(dirty)\n",
    "            loss = criterion(outputs, clean)\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss = running_loss / len(trainloader)\n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        ## validation ## \n",
    "        validation_loss = 0.0\n",
    "        net.eval()  \n",
    "        for dirty, clean in validationloader:\n",
    "            dirty,clean=dirty.to(device),clean.to(device)\n",
    "            optimizer.zero_grad()            \n",
    "            outputs = net(dirty)\n",
    "            loss = criterion(outputs, clean)\n",
    "            validation_loss += loss.item()\n",
    "        loss = validation_loss / len(validationloader)\n",
    "        valid_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, NUM_EPOCHS, loss))\n",
    "        save_decoded_image(dirty.cpu().data, name='./'+path+'/noisy{}.png'.format(epoch))\n",
    "        save_decoded_image(outputs.cpu().data, name='./'+path+'/denoised{}.png'.format(epoch))\n",
    "        save_decoded_image(clean.cpu().data, name='./'+path+'/clean{}.png'.format(epoch))\n",
    "    return net,train_loss,valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_reconstruction(net, testloader,path):\n",
    "    pnsr_1_list = []\n",
    "    pnsr_2_list = []\n",
    "    pnsr_3_list = []\n",
    "    index = 0\n",
    "    for dirty,clean in tqdm((testloader)):\n",
    "        dirty=dirty.to(device)\n",
    "        outputs = net(dirty)\n",
    "        dirty  = dirty.cpu().data\n",
    "        outputs = outputs.cpu().data\n",
    "        # psnr #\n",
    "        #psnr_1 = cv2.PSNR(clean.detach().numpy(), outputs.detach().numpy())\n",
    "        #psnr_2 = cv2.PSNR(clean.detach().numpy(),dirty.detach().numpy())\n",
    "        #psnr_3 = cv2.PSNR(dirty.detach().numpy(), outputs.detach().numpy())\n",
    "        psnr_1 = cv2.PSNR(np.array(clean), np.array(outputs))\n",
    "        psnr_2 = cv2.PSNR(np.array(clean), np.array(dirty))\n",
    "        psnr_3 = cv2.PSNR(np.array(dirty), np.array(outputs))\n",
    "        pnsr_1_list.append(psnr_1)\n",
    "        pnsr_2_list.append(psnr_2)\n",
    "        pnsr_3_list.append(psnr_3)\n",
    "        save_decoded_image(dirty, name='./'+path+'/noisy{}.png'.format(index))\n",
    "        save_decoded_image(outputs, name='./'+path+'/denoised{}.png'.format(index))\n",
    "        save_decoded_image(clean, name='./'+path+'/clean{}.png'.format(index))\n",
    "        index = index +1\n",
    "    return net,pnsr_1_list,pnsr_2_list,pnsr_3_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trwOXqGCW02U"
   },
   "source": [
    "TODO_ comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIuHxkdao7YJ",
    "outputId": "bd7c8c73-da27-494f-aa9d-31f6b90695f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (enc1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (enc2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (enc3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (enc4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dec1): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (dec2): ConvTranspose2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (dec3): ConvTranspose2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (dec4): ConvTranspose2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (out): Conv2d(64, 1, kernel_size=(2, 2), stride=(1, 1), padding=(13, 13))\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = get_device()\n",
    "print(device)\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBe1Nkf7WyEe"
   },
   "source": [
    "TODO_ comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ih3ctZc-BGSL",
    "outputId": "f48f986d-62f4-4a41-e1c3-63cb483c3b0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'cupy.core.core.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-61d6b29fadd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmake_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_VALIDATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmake_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_GRAPH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidationLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPATH_VALIDATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-5899dc1805f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, validationloader, NUM_EPOCHS, path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdirty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mdirty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-5d4550f4a407>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mxNoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxNoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mxClean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxClean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be PIL Image or ndarray. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'cupy.core.core.ndarray'>"
     ]
    }
   ],
   "source": [
    "make_dir(PATH_VALIDATION)\n",
    "make_dir(PATH_GRAPH)\n",
    "net,train_loss,validation_loss = train(net, trainLoader,validationLoader, NUM_EPOCHS,PATH_VALIDATION)\n",
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.title('Train Loss & Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig(PATH_GRAPH+'/graph_loss_train_validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized\n"
     ]
    }
   ],
   "source": [
    "print(\"finalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66jt9LvVWzKk"
   },
   "source": [
    "TODO_ comentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k0nIxLCBBAm",
    "outputId": "89fcddc4-9a56-4b76-cebc-0708ca590509"
   },
   "outputs": [],
   "source": [
    "make_dir(PATH_TEST) \n",
    "net,pnsr_1_list,pnsr_2_list,pnsr_3_list = test_image_reconstruction(net, testLoader,PATH_TEST)\n",
    "plt.hist(pnsr_1_list,  linewidth=1, label ='clean-output')\n",
    "plt.hist(pnsr_2_list,  linewidth=1, label = 'clean-dirty')\n",
    "plt.hist(pnsr_3_list, linewidth=1, label = 'dirty-output')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(PATH_GRAPH+'/graph_psnr.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dir(PATH_MODEL_SAVE) \n",
    "torch.save(net, PATH_MODEL_SAVE+'/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(PATH_MODEL_SAVE+'/model.pkl')\n",
    "net,pnsr_1_list,pnsr_2_list,pnsr_3_list = test_image_reconstruction(net, testLoader,PATH_TEST)\n",
    "plt.hist(pnsr_1_list,  linewidth=1, label ='clean-output')\n",
    "plt.hist(pnsr_2_list,  linewidth=1, label = 'clean-dirty')\n",
    "plt.hist(pnsr_3_list, linewidth=1, label = 'dirty-output')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image 28x28 & PSF Gauss 28x28**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**info image**: image size = 28x28, psf size = 28x28, type psf = gauss, dirty size = 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_psf(PATH_PSF_SAVE,TYPE_PSF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_two(data_image[0],data_dirty[0],'image','dirty image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info Dataset**:\n",
    "size dataset = 10.000,\n",
    "batch = 2,\n",
    "train percentage = 70%,\n",
    "validation percentage = 20%,\n",
    "test percentage = 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info Neural Network**: number of epochs = 2, learning rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.title('Train Loss')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train Loss vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.title('Valid Loss')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loss vs Test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.title('Train Loss vs Test Loss')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pnsr - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pnsr_1_list,  linewidth=1, label ='clean-output')\n",
    "plt.hist(pnsr_2_list,  linewidth=1, label = 'clean-dirty')\n",
    "plt.hist(pnsr_3_list, linewidth=1, label = 'dirty-output')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "clean = cv2.imread(PATH_TEST+'/clean'+str(10)+'.png')\n",
    "dirty = cv2.imread(PATH_TEST+'/noisy'+str(10)+'.png')\n",
    "output =  cv2.imread(PATH_TEST+'/denoised'+str(10)+'.png')\n",
    "display(clean,'clean')\n",
    "display(dirty,'dirty')\n",
    "display(output,'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ZOysBVxXLNDq",
    "uKW5tIafnchl"
   ],
   "name": "DeepLearning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
